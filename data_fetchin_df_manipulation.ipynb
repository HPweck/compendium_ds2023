{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data fetching and Dataframe manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO: \n",
    "- Add .env file \n",
    "- Add keggle csv\n",
    "- Add Short SQL overviw \n",
    "- Tipps for SQL, name and describe libraries that can be used for SQL (psycopg2 and )\n",
    "\n",
    "- MAKE IT RUN "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a connection to a PostgreSQL database with Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to create a connection to our PostgreSQL database we need the following information:\n",
    "\n",
    "- host = the address of the machine the database is hosted on\n",
    "- port = the virtual gate number through which communication will be allowed\n",
    "- database = the name of the database\n",
    "- user = the name of the user\n",
    "- password = the password of the user\n",
    "\n",
    "Because we don't want that the database information is published on github we put it into a .env file which is added into the gitignore. \n",
    "In these kind of files you can store information that is not supposed to be published.\n",
    "With the `dotenv` package you can read the `.env` files and get the variables.\n",
    "The file was 'force added' to the repo using ```git add -f .env``` command. Please follow instructions inside the file to ensure you have the right credentials inside. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using psycopg2\n",
    "\n",
    "import pandas as pd # to read sql data into a pandas dataframe\n",
    "import psycopg2 # to connect to SQL database\n",
    "import os # provides functions for interacting with operating system\n",
    "from dotenv import load_dotenv # reads key-value pairs from a .env file and can set them as environment variables\n",
    "\n",
    "load_dotenv() # take environment variables from .env\n",
    "DATABASE = os.getenv('DATABASE')\n",
    "USER_DB = os.getenv('USER_DB')\n",
    "PASSWORD = os.getenv('PASSWORD')\n",
    "HOST = os.getenv('HOST')\n",
    "PORT = os.getenv('PORT')\n",
    "\n",
    "\n",
    "# Create / open connection object conn (no need to edit code)\n",
    "conn = psycopg2.connect(\n",
    "    database=DATABASE,\n",
    "    user=USER_DB,\n",
    "    password=PASSWORD,\n",
    "    host=HOST,\n",
    "    port=PORT\n",
    ")\n",
    "\n",
    "cur = conn.cursor() # create cursor for our opened connection in object conn\n",
    "\n",
    "query_to_run = \"\"\"\n",
    "    SELECT *\n",
    "    FROM eda.king_county_house_details\n",
    "    JOIN eda.king_county_house_sales\n",
    "    ON eda.king_county_house_details.id = eda.king_county_house_sales.house_id;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "cur.fetchall() # gets data called by query\n",
    "df_psycopg = pd.read_sql(query_to_run, conn) # read queried data from SQL database into pandas dataframe\n",
    "\n",
    "conn.close() #close the connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### same with  SQLALCHEMY\n",
    "from sqlalchemy import create_engine # for creating an engine\n",
    "\n",
    "#read the database string DB_STRING from the .env\n",
    "load_dotenv()\n",
    "\n",
    "DB_STRING = os.getenv('DB_STRING') # gets database string DB_STRING from .env file and assigns it as value for new variable DB_STRING\n",
    "db = create_engine(DB_STRING) # creates engine from database string DB_STRING\n",
    "#import the data to a pandas dataframe\n",
    "query_string = \"SELECT * FROM datasets.kaggle_survey\" # write SQL-query into variable query_string\n",
    "df_sqlalchemy = pd.read_sql(query_string, db) # read queried data from SQL database into pandas dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL & Python shorts: \n",
    "\n",
    "Python: \n",
    "\n",
    "To just execute an SQL query without download \n",
    "\n",
    ">```cur.execute(query_to_run) ```\n",
    "\n",
    "SQL: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and write CSV files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the data to a csv-file\n",
    "df_sqlalchemy.to_csv('kaggle_survey.csv',index=False)\n",
    "\n",
    "# read csv table into the dataframe\n",
    "df_joined_table = pd.read_csv('kaggle_survey.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Data\n",
    "#### Creating data frames with Pandas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: from a CSV \n",
    "df0 = pd.read_csv('kaggle_survey.csv') \n",
    "\n",
    "# 1: Form a list of dictionary \n",
    "data_lst = [{'a': 1}, {'b':5}, {'c': 4}] # col will be a, b, c \n",
    "df1 = pd.DataFrame(data_lst)\n",
    "\n",
    "# 2: From a Numpy array \n",
    "data2 = np.array([[1, 2, 3], [4, 5, 6]]) # each index will be \n",
    "df2 = pd.DataFrame(data2, columns=['Column1', 'Column2', 'Column3']) \n",
    "\n",
    "# 3: From a dictionary \n",
    "data3 = {\n",
    "    'Column1': [1, 2, 3, 4],\n",
    "    'Column2': ['A', 'B', 'C', 'D']\n",
    "}\n",
    "\n",
    "df3 = pd.DataFrame(data3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting an insight of the data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.head() # show top of the data frame, can take an integer in () to limit the amount of lines \n",
    "\n",
    "df0.tail() # same with bottom \n",
    "\n",
    "df0.shape # will return us the number of rows and columns of our DataFrame\n",
    "\n",
    "df1.columns # will show col names \n",
    "\n",
    "df3.info() # will output Non-Null Count and data type for each col \n",
    "\n",
    "df2.describe() # to get some statistics, min, max, mean, quartiles, std for numeric values \n",
    "\n",
    "df4 = df2.copy() # make a copy of your dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulate the column names and stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list column names\n",
    "cols = df2.columns.tolist()\n",
    "\n",
    "# replace space with _\n",
    "cols = [col.replace(' ', '_') for col in cols]\n",
    "# reassign new column names to dataframe\n",
    "df2.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with data in the data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df3['Column1'] # grab a column in bracket notation \n",
    "\n",
    "df3.Column1 # grab a column in dot notation \n",
    "\n",
    "df3[['Column1', 'Column2']] # can also grab more than one col \n",
    "\n",
    "df3[:3] # This will grab from the beginning up to but not including the row at index 3. So rows 0, 1, 2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with data in the data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7a35bba081246a577863ed5357213b0bf3e2936bc08045816acb79d76e359dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
